{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation and Least Squares Regression.\n",
    "```\n",
    "- In this lecture and series of exercises you will learn:\n",
    "    - The concepts of variance and covariance of data.\n",
    "    - What the correlation coefficient is and how it relates to covariance.\n",
    "    - How linear regression relates to correlation.\n",
    "    - How to transform data with nonlinear relationship so that they may be analyzed with linear regression.\n",
    "    - The extension of linear regression to multiple dimensions.\n",
    "    - Application of the t-test to determine the significance of predictors in a multidimensional linear model.\n",
    "```\n",
    "#### What is your ability after finish this lecture.\n",
    "\n",
    " - Calculate the correlation coefficient for a 2D data set.\n",
    " - Find the least squares solution for a multi-variate linear regression problem.\n",
    " - Apply linear regression to nonlinear relationships through **variable transforms** .\n",
    " - Perform model selection on the predictors using a t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bofre start you need to install the following packages.\n",
    "\n",
    "```\n",
    "\n",
    "As part of this lecture, you will be applying all of the above concepts to analyze real data in the context of astronomy. To do this, you will need a data analysis environment set up.\n",
    "\n",
    "We recommend using Python, with the numpy and scipy packages. The data and solutions will be given in Python using these libraries. However, you are welcome to use any programming language or environment that you wish.\n",
    "\n",
    "You will also be asked to visualize the data. In Python, you can do this with the matplotlib library.\n",
    "\n",
    "For example, a scatter plot can be creating using\n",
    "```py\n",
    "import matplotlib.pyplot as plt # import the library\n",
    "plt.scatter(Xs, Ys) # Create the scatter plot, Xs and Ys are two numpy arrays of the same length\n",
    "plt.show() # Display the plot you just created.\n",
    "# A line plot can be created using\n",
    "\n",
    "plt.plot(Xs, Ys)\n",
    "# This will draw a line through the X, Y pairs defined by the Xs and Ys numpy arrays.\n",
    "\n",
    "# When working with matrices, numpy provides some convenient facilities. For example, to find the inverse of a matrix, use\n",
    "\n",
    "import numpy as np\n",
    "np.linalg.inv(matrix_to_invert)\n",
    "# The scipy package provides statistical distributions. For example, to calculate p-values for the t-distribution, you can use the survival function (sf):\n",
    "\n",
    "import scipy.stats\n",
    "scipy.stats.t.sf(T, num_degrees_of_freedom)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation. --> `part 2`\n",
    "\n",
    "- what we nee to learn on this unit?\n",
    "    - Build up the concept of correlations from the more basic concepts of variance and covariance of data.\n",
    "    - Apply the concept of correlation to data from astronomy.\n",
    "\n",
    "- what is Covariance(التغاير)?\n",
    "  - Covariance is a measure of the amount of correlation between two variables.\n",
    "  - Conariance Eqution:\n",
    "    - $Cov(X,Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\overline X)(Y_i - \\overline Y)$\n",
    "    - $ \\overline X = \\frac{1}{n} \\sum_{i=1}^{n} X_i $  -> `mean of X`\n",
    "    - $ \\overline Y = \\frac{1}{n} \\sum_{i=1}^{n} Y_i $  -> `mean of Y`\n",
    "    - X_i is the ith value of X.\n",
    "    - Y_i is the ith value of Y.\n",
    "    - n is the number of values in X and Y.\n",
    "    - $Cov(X,Y)$ is the covariance of X and Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Create the data\n",
    "X = np.random.normal(0, 1, 100)\n",
    "Y = np.random.normal(0, 1, 100)\n",
    "\n",
    "\n",
    "# Calculate the covariance\n",
    "Cov = np.cov(X, Y)[0, 1]\n",
    "\n",
    "\n",
    "# Calculate the correlation coefficient\n",
    "Corr = Cov / (np.std(X) * np.std(Y))\n",
    "\n",
    "\n",
    "# Plot the data\n",
    "plt.scatter(X, Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Point about Covariance.\n",
    "- if the mean value  of $\\overline X = sum_{i=1}^{n} X_i / n$ and $\\overline Y = sum_{i=1}^{n} Y_i / n$, to cheange thats we will applying the `Bessel's correction`. \n",
    "\n",
    "    - $Cov(X,Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\overline X)(Y_i - \\overline Y)$.\n",
    "\n",
    "---\n",
    "- What does covariance demonstrate?\n",
    "    - Covariance measures the direction of the relationship between two variables. A positive covariance means that both variables tend to be high or low at the same time. A negative covariance means that when one variable is high, the other tends to be low.\n",
    "--- \n",
    "- What is covariance and variance?\n",
    "    - Variance and covariance are mathematical terms frequently used in statistics and probability theory. Variance refers to the spread of a data set around its mean value, while a covariance refers to the measure of the directional relationship between two random variables.\n",
    "---\n",
    "- How do you interpret covariance in statistics?\n",
    "    \n",
    "    ![covarinance](./assets/img/covariance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "```text\n",
    "In this exercise, we will investigate the correlation present in astronomical data observed by Edwin Hubble in the period surrounding 1930.\n",
    "\n",
    "Hubble was interested in the motion of distant galaxies. He recorded the apparent velocity of these galaxies – the speed at which they appear to be receding away from us – by observing the spectrum of light they emit, and the distortion thereof caused by their relative motion to us. He also determined the distance of these galaxies from our own by observing a certain kind of star known as a Cepheid variable which periodically pulses. The amount of light this kind of star emits is related to this pulsation, and so the distance to any star of this type can be determined by how bright or dim it appears.\n",
    "\n",
    "The following figure shows his data. The Y-axis is the apparent velocity, measured in kilometers per second. Positive velocities are galaxies moving away from us, negative velocities are galaxies that are moving towards us. The Y-axis is the distance of the galaxy from us, measured in mega-parsecs (Mpc); one parsec is 3.26 light-years, or 30.9 trillion kilometers\n",
    "```\n",
    "\n",
    "![Hubble data](./assets/img/images_hubble_regression.png)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hubble Dataset\n",
    "\n",
    "Xs = np.array([0.0339, 0.0423, 0.213, 0.257, 0.273, 0.273, 0.450, 0.503, 0.503, \\\n",
    "0.637, 0.805, 0.904, 0.904, 0.910, 0.910, 1.02, 1.11, 1.11, 1.41, \\\n",
    "1.72, 2.03, 2.02, 2.02, 2.02])\n",
    "\n",
    "Ys = np.array([-19.3, 30.4, 38.7, 5.52, -33.1, -77.3, 398.0, 406.0, 436.0, 320.0, 373.0, \\\n",
    "93.9, 210.0, 423.0, 594.0, 829.0, 718.0, 561.0, 608.0, 1.04E3, 1.10E3, \\\n",
    "840.0, 801.0, 519.0])\n",
    "\n",
    "N = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean for dataset.\n",
    "\n",
    "- why we need to calculate the mean of the dataset?\n",
    "    - to calculate the covariance.\n",
    "    - to calculate the correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_X =  0.9199250000000001\n",
      "mu_Y =  425.6175\n"
     ]
    }
   ],
   "source": [
    "# mean for Xs and Ys\n",
    "mu_X = np.mean(Xs)  #Or Xs.sum()/N\n",
    "mu_Y = np.mean(Ys)  #Or Ys.sum()/N\n",
    "print(\"mu_X = \", mu_X)\n",
    "print(\"mu_Y = \", mu_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard deviation for dataset.\n",
    "\n",
    "- why we need to calculate the standard deviation of the dataset?\n",
    "    - to calculate the correlation coefficient.\n",
    "- how many equations we need to calculate the standard deviation of the dataset?\n",
    "    - 2 equations.\n",
    "- what is two equations?\n",
    "    - $ \\sigma_X = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\overline X)^2} $\n",
    "    - $ \\sigma_Y = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (Y_i - \\overline Y)^2} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_X =  0.6533948258734996\n",
      "sigma_Y =  348.7336574977229\n"
     ]
    }
   ],
   "source": [
    "# standard deviation for Xs and Ys\n",
    "sigma_X = np.sqrt(np.sum((Xs - mu_X)**2)/(N-1))\n",
    "sigma_Y = np.sqrt(np.sum((Ys - mu_Y)**2)/(N-1))\n",
    "print(\"sigma_X = \", sigma_X)\n",
    "print(\"sigma_Y = \", sigma_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let us now calculate the convariance of the dataset.\n",
    "\n",
    "we will use this equation:\n",
    "\n",
    "$ Cov(X,Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\overline X)(Y_i - \\overline Y)$\n",
    "\n",
    "- $\\sum_{i=1}^{n}(X_i - \\overline X)$.\n",
    "- $\\sum_{i=1}^{n}(Y_i - \\overline Y)$.\n",
    "- $n$ is the number of values in X and Y.\n",
    "- $n-1$ is the number of values in X and Y minus 1.\n",
    "- $X_i$ is the ith value of X.\n",
    "- $Y_i$ is the ith value of Y.\n",
    "- $\\overline X$ is the mean of X.\n",
    "- $\\overline Y$ is the mean of Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covariance = 191.20706528260868\n"
     ]
    }
   ],
   "source": [
    "# Now, calculate the sample covariance for the Hubble dataset to three significant figures:\n",
    "covariance = ((Xs - mu_X) * (Ys - mu_Y)).sum() / (N - 1)\n",
    "print(\"covariance =\", covariance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Correlation Coefficient --> `part 3`\n",
    "\n",
    "- what is differnt between correlation coefficient and covariance?\n",
    "    - correlation coefficient is a measure of the strength of the linear relationship between two variables.\n",
    "    - covariance is a measure of the amount of correlation between two variables.\n",
    "- if X and Y are positively correlated, the correlation coefficient is positive.\n",
    "- if X and Y are negatively correlated, the correlation coefficient is negative.\n",
    "- if X and Y are independent, the correlation coefficient is zero.\n",
    "- if X and Y are correlation coefficient is zero when X and Y are uncorrelated(remember that this dose mean that the two variables are independent).\n",
    "- Correlation don't take any units.\n",
    "    - exmaple on Hubble dataset correlation coefficient is 0.9 with out unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr = 0.8391399162310663\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation coefficient\n",
    "Corr = covariance / (sigma_X * sigma_Y)\n",
    "print(\"Corr =\", Corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratics.\n",
    "\n",
    "- what is a quadratic?\n",
    "    - a quadratic is a function of the form $f(x) = ax^2 + bx + c$.\n",
    "        - $f(x)$ is the function.\n",
    "        - $a$ is the coefficient of the quadratic.\n",
    "        - $b$ is the coefficient of the linear term.\n",
    "        - $c$ is the constant term.\n",
    "- what is the quadratic formula?\n",
    "    - the quadratic formula is a way of finding the roots of a quadratic equation.\n",
    "    - the quadratic formula is $x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$\n",
    "    - $b^2 - 4ac$ is the discriminant.\n",
    "    - $b$ is the coefficient of the linear term.\n",
    "    - $a$ is the coefficient of the quadratic term.\n",
    "    - $c$ is the constant term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to construct a linear predictive model\n",
    "- simple linear regression equation:\n",
    "    - $y = \\beta_0 + \\beta_1 x$.\n",
    "        - $y$ is the dependent variable.\n",
    "        - $x$ is the independent variable.\n",
    "        - $\\beta_0$ is the intercept.\n",
    "        - $\\beta_1$ is the slope.\n",
    "    - slop equation:\n",
    "        - $\\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\bar{x}) (y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2}$.\n",
    "    - intercept equation:\n",
    "        - $\\beta_0 = \\bar{y} - \\beta_1 \\bar{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goodness fit metric  (R-squared)\n",
    "is a measure of how well a regression model fits the data.\n",
    "\n",
    "$R^2$ = 1- $\\frac{SS_{res}}{SS_{tot}}$\n",
    "\n",
    "- $R^2$ is a statistical measure that represents the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model. the independent variable.\n",
    "\n",
    "- $SS_{res}$ is the sum of the squared residuals.\n",
    "    - $SS_{res} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
    "        -   $y_i$ is the actual value of the dependent variable.\n",
    "        -   $\\hat{y}_i$ is the predicted value of the dependent variable.\n",
    "\n",
    "- $SS_{tot}$ is the sum of the squared total.\n",
    "    - $SS_{tot} = \\sum_{i=1}^{n} (y_i - \\overline{y})^2$\n",
    "        - $\\overline{y}$ is the mean of the dependent variable.\n",
    "        - $y_i$ is the actual value of the dependent variable.\n",
    "\n",
    "#### What does R-squared tell us in regression?\n",
    "R-squared is a goodness-of-fit measure for linear regression models. This statistic indicates the percentage of the variance in the dependent variable that the independent variables explain collectively.\n",
    "\n",
    "#### Is a higher R-squared better?\n",
    "In general, the higher the R-squared, the better the model fits your data.\n",
    "\n",
    "#### when use R-squared to evaluate a model?\n",
    "R-squared measures the strength of the relationship between your model and the dependent variable on a convenient 0 – 100% scale. After fitting a linear regression model, you need to determine how well the model fits the data.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goodness of fit metric (R-squared)\n",
    "def r_squared(xs, ys):\n",
    "    mean = np.mean(ys)\n",
    "    ss_tot = sum((ys - mean) ** 2)\n",
    "    ss_res = sum((ys - xs) ** 2)\n",
    "    r_squared = 1 - (ss_res / ss_tot)\n",
    "    return r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line reqgression model for the Hubble dataset\n",
    "def line_regression(xs, ys):\n",
    "    slope = covariance / (sigma_X * sigma_Y)\n",
    "    intercept = mu_Y - slope * mu_X\n",
    "    return slope, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slope = 0.8391399162310663\n",
      "intercept = 424.8455542125611\n"
     ]
    }
   ],
   "source": [
    "slope , intercept = line_regression(Xs, Ys)\n",
    "print(\"slope =\", slope)\n",
    "print(\"intercept =\", intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use some hubble data to test the line regression model\n",
    "Xs_test = np.array([0.0339, 0.0423, 0.213, 0.257, 0.273, 0.273, 0.450, 0.503, 0.503, \\\n",
    "0.637, 0.805, 0.904, 0.904, 0.910, 0.910, 1.02, 1.11, 1.11, 1.41, \\\n",
    "1.72, 2.03, 2.02, 2.02, 2.02])\n",
    "Ys_test = np.array([-19.3, 30.4, 38.7, 5.52, -33.1, -77.3, 398.0, 406.0, 436.0, 320.0, 373.0, \\\n",
    "93.9, 210.0, 423.0, 594.0, 829.0, 718.0, 561.0, 608.0, 1.04E3, 1.10E3, \\\n",
    "840.0, 801.0, 519.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ys_pred = [424.87400106 424.88104983 425.02429101 425.06121317 425.07463941\n",
      " 425.07463941 425.22316717 425.26764159 425.26764159 425.38008634\n",
      " 425.52106185 425.6041367  425.6041367  425.60917154 425.60917154\n",
      " 425.70147693 425.77699952 425.77699952 426.02874149 426.28887487\n",
      " 426.54900824 426.54061684 426.54061684 426.54061684]\n"
     ]
    }
   ],
   "source": [
    "# predict the Hubble data using the line regression model\n",
    "Ys_pred = intercept + slope * Xs_test\n",
    "print(\"Ys_pred =\", Ys_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_of_squared_residuals = 2789775.007231944\n"
     ]
    }
   ],
   "source": [
    "sum_of_squared_residuals = sum((Ys_test - Ys_pred) ** 2)\n",
    "print(\"sum_of_squared_residuals =\", sum_of_squared_residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum_of_squared_total = 2797148.76905\n"
     ]
    }
   ],
   "source": [
    "sum_of_squared_total = sum((Ys_test - np.mean(Ys_test)) ** 2)\n",
    "print(\"sum_of_squared_total =\", sum_of_squared_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 = 0.0026361707677637902\n"
     ]
    }
   ],
   "source": [
    "r2 = 1 - (sum_of_squared_residuals / sum_of_squared_total)\n",
    "print(\"r2 =\", r2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
